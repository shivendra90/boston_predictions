## The Boston Real Estate Predictions

The Boston pricing predictions is the 4th and final part of Udacity's nanodegree on Machine Learning Foundation. This project involves the basics of a machine learning research design and shares the most important of ML research pipelines including reading, cleaning, modifying data and extracting valuable statistical insights.

A machine learning algorithm typically puts the researcher into predicting a variable that is always dependent on another variable(s). In several cases, there can be numerous dependent variables depending on several predictor variables. So, machine learning (and deep learning as well) are in core essence an extension of the well known regression analysis which is primarily the oldest known machine learning technique; the only difference being that before elaborate computing got invented, regression analysis were mostly used to explain the case-effect relationships in nature and thus try to predict future tendencies. The regression on son's heights and their parent's heights comes to mind as one of the oldest regression analysis conducted.

In the `boston_housing` project, similar such stuff is carried out through multilinear regression fits of varying degrees. The notebook provided in this repo comes prebuilt in Udacity's cloud workbench and the student is required to perform only the necessary tasks to form one predictive document.

The data read in here comes from UCI's machine learning hub that provides a number of datasets for practice and research purposes. The original data containing over 18 variables, the `boston_housing` notebook uses only 3 of them that instructors felt are the most influential in deciding pricing of homes in a Boston area.

The notebook uses several modules, most notably being `sklearn` and its inbuilt plotting functions. A custom module called `visuals` too is provided which is a .py file that reads in several functions to plot the performance and complexity curves for training and testing data. These are essential parts of any learning algorithm since without them its impossible to be aware of the accuracy of the model being worked upon.

Finally, there are the ending print statements that make use of the model's predictions to print out the results. As will be seen in the notebook, there are three clients each one having his own predicted price according to number of rooms (`RM`), percentage of population living under poverty in percentage (`LSTAT`) and the ratio that represents number of students available per teacher (`PTRATIO`). The most reasonable prediction comes out to be that of client 2. Comparing these results with some of the descriptive statistics extracted in the beginning of the document will suggest that the model is satisfactory in its performance and predictions.

Please do note that this notebook runs on Python 3.6. Earlier versions of this language till 2.7 won't work partly because of the way `print()` statements work and the implementation of overall functions and modules in the newer version. Also do note that there are some modules that have been deprecated and won't be provided in sklearn 0.20. However, because of some new additions and changes to the syntaxes of functions in the new module, certain modifications to the code is required but cannot be performed since that would damage the overall structure of the document and render it unusable. I will have to research on how the new functions work and what arguments they require and accordingly introduce changes.
